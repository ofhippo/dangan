{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    import cPickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = cPickle.load(fo)\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_1 = unpickle('cifar-10-batches-py/data_batch_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 3072)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = batch_1['data']\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train = batch_1['labels']\n",
    "len(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x115bf2dd0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFwAAABZCAYAAACzIkPrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10eda0490>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import scipy.misc\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "plt.figure(figsize =(1,1))\n",
    "image = np.swapaxes(X_train[9].reshape(32, 32, 3, order='F'), 0,1)\n",
    "image = scipy.misc.imresize(image, (32,32)) \n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x115ccb150>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRsCBxP4Lk/bymjUC2LgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10ea8f2d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = np.swapaxes(X_train[9].reshape(32, 32, 3, order='F'), 0,1)\n",
    "image = scipy.misc.imresize(image, (8,8)) \n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def leaky_relu_and_bn(X, bn_name, alpha=0.3):\n",
    "    X = tf.layers.batch_normalization(X, name=bn_name)\n",
    "    return tf.nn.relu(X) - alpha * tf.nn.relu(-X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Discriminator\n",
    "# -----\n",
    "# Phase: 0 (initial)\n",
    "# Input: 3 x 4 x 4\n",
    "\n",
    "# Block: from_rgb_4\n",
    "# c1 (from_rbg): 128 x 4 x 4\n",
    "\n",
    "# Block: out\n",
    "# c3: 128 x 4 x 4\n",
    "# c4: 128 x 1 x 1\n",
    "# fc: 1 x 1 x 1\n",
    "\n",
    "# -----\n",
    "# Phase: 1 (add 1)\n",
    "# Input: 3 x 8 x 8\n",
    "\n",
    "# Block: from_rgb_8\n",
    "# c1 (from_rbg): 64 x 8 x 8\n",
    "\n",
    "# Block: added_8_to_4\n",
    "# c3: 64 x 8 x 8\n",
    "# c3: 128 x 8 x 8\n",
    "# dn: 128 x 4 x 4\n",
    "\n",
    "# Block: out\n",
    "# c3: 128 x 4 x 4\n",
    "# c4: 128 x 1 x 1\n",
    "# fc: 1 x 1 x 1\n",
    "\n",
    "# -----\n",
    "# Phase: 2 (add 2)\n",
    "# Input: 3 x 16 x 16\n",
    "\n",
    "# Block: from_rgb_16\n",
    "# c1 (from_rbg): 32 x 16 x 16\n",
    "\n",
    "# Block: added_16_to_8\n",
    "# c3: 32 x 16 x 16\n",
    "# c3: 64 x 16 x 16\n",
    "# dn: 64 x 8 x 8\n",
    "\n",
    "# Block: added_8_to_4\n",
    "# c3: 64 x 8 x 8\n",
    "# c3: 128 x 8 x 8\n",
    "# dn: 128 x 4 x 4\n",
    "\n",
    "# Block: out\n",
    "# c3: 128 x 4 x 4\n",
    "# c4: 128 x 1 x 1\n",
    "# fc: 1 x 1 x 1\n",
    "\n",
    "# -----\n",
    "# Phase: 3 (add 3)\n",
    "# Input: 3 x 32 x 32\n",
    "\n",
    "# Block: from_rgb_32\n",
    "# c1 (from_rbg): 16 x 32 x 32\n",
    "\n",
    "# Block: added_32_to_16\n",
    "# c3: 16 x 32 x 32\n",
    "# c3: 32 x 32 x 32\n",
    "# dn: 32 x 16 x 16\n",
    "\n",
    "# Block: added_16_to_8\n",
    "# c3: 32 x 16 x 16\n",
    "# c3: 64 x 16 x 16\n",
    "# dn: 64 x 8 x 8\n",
    "\n",
    "# Block: added_8_to_4\n",
    "# c3: 64 x 8 x 8\n",
    "# c3: 128 x 8 x 8\n",
    "# dn: 128 x 4 x 4\n",
    "\n",
    "# Block: out\n",
    "# c3: 128 x 4 x 4\n",
    "# c4: 128 x 1 x 1\n",
    "# fc: 1 x 1 x 1\n",
    "\n",
    "# ><><><><><><><><><><><><\n",
    "\n",
    "# Generator\n",
    "# ------\n",
    "# Phase: 0 (Initial)\n",
    "# Input z: 128 x 1 x 1\n",
    "\n",
    "# Block: initial\n",
    "# c4: 128 x 4 x 4\n",
    "# c3: 128 x 4 x 4\n",
    "\n",
    "# Block: to_rgb_4\n",
    "# c1 (to_rgb): 3 x 4 x 4\n",
    "\n",
    "# ----\n",
    "# Phase: 1 (add 1)\n",
    "# Input z: 128 x 1 x 1\n",
    "\n",
    "# Block: initial\n",
    "# c4: 128 x 4 x 4\n",
    "# c3: 128 x 4 x 4\n",
    "\n",
    "# Block: added_4_to_8\n",
    "# up: 128 x 8 x 8\n",
    "# c3: 64 x 8 x 8\n",
    "# c3: 64 x 8 x 8\n",
    "\n",
    "# Block: to_rgb_8\n",
    "# c1 (to_rgb): 3 x 8 x 8\n",
    "\n",
    "# -----\n",
    "# Phase: 2 (add 2)\n",
    "# Input z: 128 x 1 x 1\n",
    "\n",
    "# Block: initial\n",
    "# c4: 128 x 4 x 4\n",
    "# c3: 128 x 4 x 4\n",
    "\n",
    "# Block: added_4_to_8\n",
    "# up: 128 x 8 x 8\n",
    "# c3: 64 x 8 x 8\n",
    "# c3: 64 x 8 x 8\n",
    "\n",
    "# Block: added_8_to_16\n",
    "# up: 64 x 16 x 16\n",
    "# c3: 32 x 16 x 16\n",
    "# c3: 32 x 16 x 16\n",
    "\n",
    "# Block: to_rgb_16\n",
    "# c1 (to_rgb): 3 x 16 x 16\n",
    "\n",
    "# ----\n",
    "# Phase: 3 (add 3)\n",
    "# Input z: 128 x 1 x 1\n",
    "\n",
    "# Block: initial\n",
    "# c4: 128 x 4 x 4\n",
    "# c3: 128 x 4 x 4\n",
    "\n",
    "# Block: added_4_to_8\n",
    "# up: 128 x 8 x 8\n",
    "# c3: 64 x 8 x 8\n",
    "# c3: 64 x 8 x 8\n",
    "\n",
    "# Block: added_8_to_16\n",
    "# up: 64 x 16 x 16\n",
    "# c3: 32 x 16 x 16\n",
    "# c3: 32 x 16 x 16\n",
    "\n",
    "# Block: added_16_to_32\n",
    "# up: 32 x 32 x 32\n",
    "# c3: 16 x 32 x 32\n",
    "# c3: 16 x 32 x 32\n",
    "\n",
    "# Block: to_rgb_32\n",
    "# c1 (to_rgb): 3 x 32 x 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Config:\n",
    "batch_size = 32\n",
    "num_images_before_adding_block_constant = 10\n",
    "num_epochs = 1000000000\n",
    "d_warm_up = 0\n",
    "verbose = True\n",
    "print_frequency = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_num_blocks_to_add_and_smoothing_coefficient(num_images_seen):\n",
    "    num_images_before_adding_block = tf.constant(num_images_before_adding_block_constant, tf.float32)\n",
    "\n",
    "    num_blocks_to_add = tf.floor(num_images_seen / num_images_before_adding_block)\n",
    "    num_blocks_to_add = tf.cond(num_blocks_to_add > 3, lambda: tf.minimum(num_blocks_to_add, tf.constant(3.0)), lambda: num_blocks_to_add)\n",
    "\n",
    "    num_images_into_phase = num_images_seen - (num_blocks_to_add * num_images_before_adding_block)  \n",
    "    smoothing_coefficient = tf.cond(num_blocks_to_add >= 3,\n",
    "        lambda: tf.constant(1.0),\n",
    "        lambda: tf.maximum(tf.constant(1.0), num_images_into_phase / (num_images_before_adding_block / 2)))\n",
    "    \n",
    "    # Don't smooth in starting resolution since there is no prior\n",
    "    smoothing_coefficient = tf.cond(tf.equal(num_blocks_to_add, 0), lambda: tf.constant(1.0), lambda: smoothing_coefficient)\n",
    "    \n",
    "    return [num_blocks_to_add, smoothing_coefficient]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def leaky_relu_and_bn(X, bn_name, alpha=0.3):\n",
    "    X = tf.layers.batch_normalization(X, name=bn_name)\n",
    "    return tf.nn.relu(X) - alpha * tf.nn.relu(-X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In: batch_size, resolution, resolution, 3\n",
    "# Out: batch_size, resolution, resolution, target_num_channels \n",
    "def from_rgb(X, resolution, target_num_channels, reuse=None):\n",
    "    with tf.variable_scope(\"from_rgb_\" + str(resolution)):\n",
    "        if (reuse):\n",
    "            tf.get_variable_scope().reuse_variables()\n",
    "        X_normalized = tf.layers.batch_normalization(X, name='bn0' + str(resolution))\n",
    "        w = tf.get_variable('w' + str(resolution), [1, 1, 3, target_num_channels], initializer=tf.truncated_normal_initializer(stddev=np.sqrt(2.0 / target_num_channels)))\n",
    "        b = tf.get_variable('b' + str(resolution), [target_num_channels], initializer = tf.truncated_normal_initializer(stddev=0.02))\n",
    "        conv = tf.nn.conv2d(X_normalized, w, [1,1,1,1], padding='SAME') + b\n",
    "        return leaky_relu_and_bn(conv, 'bn1' + str(resolution))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# In: batch_size, 4*2^phase, 4*2^phase, 3\n",
    "# Out: batch_size, 4*2^phase, 4*2^phase, 128/(2^phase)\n",
    "def from_rgb_for_phase(X, phase, reuse=None):\n",
    "    return tf.case([\n",
    "            (tf.equal(phase, tf.constant(0.0)), lambda: from_rgb(X, 4, 128, reuse)),\n",
    "            (tf.equal(phase, tf.constant(1.0)), lambda: from_rgb(X, 8, 64, reuse)),\n",
    "            (tf.equal(phase, tf.constant(2.0)), lambda: from_rgb(X, 16, 32, reuse)),\n",
    "            (tf.equal(phase, tf.constant(3.0)), lambda: from_rgb(X, 32, 16, reuse)),\n",
    "        ], default=lambda: tf.zeros((1,4,4,128)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# In: batch_size, 4*2^phase, 4*2^phase, 3\n",
    "# Out: batch_size, 4*2^phase, 4*2^phase, 128/(2^phase) \n",
    "def from_rgb_possibly_smoothed(X, phase, smoothing_coefficient):\n",
    "    from_rgb = from_rgb_for_phase(X, phase)\n",
    "    \n",
    "    def smoothed():\n",
    "        half_resolution_X = tf.nn.avg_pool(X, [1, 2, 2, 1], [1, 1, 1, 1], padding='SAME')\n",
    "        prior_from_rgb = from_rgb_for_phase(half_resolution_X, phase - 1, True)\n",
    "        return (1 - smoothing_coefficient) * prior_from_rgb + smoothing_coefficient * from_rgb\n",
    "    \n",
    "    return tf.cond(smoothing_coefficient < 1.0, smoothed, lambda: from_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In: batch_size, input_resolution, input_resolution, input_num_channels\n",
    "# Out: batch_size, input_resolution / 2, input_resolution / 2, 2 * input_num_channels\n",
    "def added_discriminator_block(X, input_resolution, input_num_channels):\n",
    "    target_resolution = input_resolution / 2\n",
    "    target_num_channels = 2 * input_num_channels\n",
    "    with tf.variable_scope(\"added_\" + str(input_resolution) + \"_to_\" + str(target_resolution)):\n",
    "        w1 = tf.get_variable('w1', [3, 3, input_num_channels, input_num_channels], initializer=tf.truncated_normal_initializer(stddev=np.sqrt(2.0 / input_num_channels)))\n",
    "        b1 = tf.get_variable('b1', [input_num_channels], initializer = tf.truncated_normal_initializer(stddev=0.02))    \n",
    "        conv1 = tf.nn.conv2d(X, w1, [1,1,1,1], padding='SAME', name='conv1') + b1\n",
    "        a1 = leaky_relu_and_bn(conv1, 'bn1')\n",
    "\n",
    "        w2 = tf.get_variable('w2', [3, 3, input_num_channels, target_num_channels], initializer=tf.truncated_normal_initializer(stddev=np.sqrt(2.0 / input_num_channels)))\n",
    "        b2 = tf.get_variable('b2', [target_num_channels], initializer = tf.truncated_normal_initializer(stddev=0.02))    \n",
    "        conv2 = tf.nn.conv2d(a1, w2, [1,1,1,1], padding='SAME', name='conv2') + b2\n",
    "        a2 = leaky_relu_and_bn(conv2, 'bn2')  \n",
    "\n",
    "        return tf.nn.avg_pool(a2, [1, 2, 2, 1], [1, 1, 1, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In: batch_size, 4, 4, 128\n",
    "# Out: batch_size, 1, 1, 1\n",
    "def discriminator_output_block(X):\n",
    "    with tf.variable_scope(\"output_block\"):\n",
    "        w1 = tf.get_variable('w1', [3, 3, 128, 128], initializer=tf.truncated_normal_initializer(stddev=np.sqrt(2.0 / 128)))\n",
    "        b1 = tf.get_variable('b1', [128], initializer = tf.truncated_normal_initializer(stddev=0.02))    \n",
    "        conv1 = tf.nn.conv2d(X, w1, [1,1,1,1], padding='SAME') + b1\n",
    "        a1 = leaky_relu_and_bn(conv1, 'bn1')\n",
    "\n",
    "        w2 = tf.get_variable('w2', [4, 4, 128, 128], initializer=tf.truncated_normal_initializer(stddev=np.sqrt(2.0 / 128)))\n",
    "        b2 = tf.get_variable('b2', [128], initializer = tf.truncated_normal_initializer(stddev=0.02))    \n",
    "        conv2 = tf.nn.conv2d(a1, w2, [1,1,1,1], padding='VALID') + b2\n",
    "        a2 = leaky_relu_and_bn(conv2, 'bn2')\n",
    "        return tf.layers.dense(a2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In: batch_size, 4*2^phase, 4*2^phase, 3\n",
    "# Out: batch_size, 1, 1, 1\n",
    "def discriminator(X, num_images_seen, reuse=False):\n",
    "    with tf.variable_scope(\"D\"):\n",
    "        if (reuse):\n",
    "            tf.get_variable_scope().reuse_variables()\n",
    "        num_blocks_to_add, smoothing_coefficient = calculate_num_blocks_to_add_and_smoothing_coefficient(num_images_seen)\n",
    "        phase = num_blocks_to_add\n",
    "        \n",
    "        X = tf.reshape(X, (batch_size, -1, -1, 3)) # TODO: Generator output shape is poorly specified\n",
    "\n",
    "        X = from_rgb_possibly_smoothed(X, phase, smoothing_coefficient)\n",
    "        \n",
    "        X = tf.cond(phase >= 3, lambda: added_discriminator_block(X, 32, 16), lambda: X)\n",
    "        X = tf.cond(phase >= 2, lambda: added_discriminator_block(X, 16, 32), lambda: X)\n",
    "        X = tf.cond(phase >= 1, lambda: added_discriminator_block(X, 8, 64), lambda: X)\n",
    "\n",
    "        return discriminator_output_block(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In: batch_size, 128, 1, 1\n",
    "# Out: batch_size, 128, 4, 4\n",
    "def initial_generator_block(z):\n",
    "    with tf.variable_scope(\"initial_block\"):\n",
    "        w1 = tf.get_variable('w1', [4, 4, 128, 128], initializer=tf.truncated_normal_initializer(stddev=np.sqrt(2.0 / 128)))\n",
    "        b1 = tf.get_variable('b1', [128], initializer = tf.truncated_normal_initializer(stddev=0.02))    \n",
    "        conv1 = tf.nn.conv2d_transpose(z, w1, [batch_size, 4, 4, 128], [1, 1, 1, 1], padding='VALID', name='conv1') + b1      \n",
    "        a1 = leaky_relu_and_bn(conv1, 'bn1')\n",
    "\n",
    "        w2 = tf.get_variable('w2', [3, 3, 128, 128], initializer=tf.truncated_normal_initializer(stddev=np.sqrt(2.0 / 128)))\n",
    "        b2 = tf.get_variable('b2', [128], initializer = tf.truncated_normal_initializer(stddev=0.02))    \n",
    "        a2 = tf.nn.conv2d_transpose(a1, w2, [batch_size, 4, 4, 128], [1, 1, 1, 1], padding='SAME', name='conv2') + b2\n",
    "        return leaky_relu_and_bn(a2, 'bn2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In: batch_size, starting_resolution, starting_resolution, starting_num_channels\n",
    "# Out: [\n",
    "#       (batch_size, 2 * starting_resolution, 2 * starting_resolution, starting_num_channels), # result after doubling\n",
    "#       (batch_size, 2 * starting_resolution, 2 * starting_resolution, starting_num_channels / 2) # block output at target resolution\n",
    "# ]\n",
    "def added_generator_block(X, starting_resolution, starting_num_channels):\n",
    "    target_resolution = 2 * starting_resolution\n",
    "    target_num_channels = starting_num_channels / 2\n",
    "    with tf.variable_scope(\"added_\" + str(starting_resolution) + \"_to_\" + str(target_resolution)):\n",
    "        double_resolution = tf.image.resize_nearest_neighbor(X, [target_resolution, target_resolution])\n",
    "        w1 = tf.get_variable('w1', [3, 3, target_num_channels, starting_num_channels], initializer=tf.truncated_normal_initializer(stddev=np.sqrt(2.0 / starting_num_channels)))\n",
    "        b1 = tf.get_variable('b1', [target_num_channels], initializer = tf.truncated_normal_initializer(stddev=np.sqrt(2.0 / target_num_channels)))\n",
    "        deconv1 = tf.nn.conv2d_transpose(double_resolution, w1, [batch_size, target_resolution, target_resolution, target_num_channels], [1,1,1,1], padding='SAME', name='deconv1') + b1\n",
    "        a1 = leaky_relu_and_bn(deconv1, 'bn1')\n",
    "\n",
    "        w2 = tf.get_variable('w2', [3, 3, target_num_channels, target_num_channels], initializer=tf.truncated_normal_initializer(stddev=np.sqrt(2.0 / target_num_channels)))\n",
    "        b2 = tf.get_variable('b2', [target_num_channels], initializer = tf.truncated_normal_initializer(stddev=0.02))\n",
    "        deconv2 = tf.nn.conv2d_transpose(a1, w2, [batch_size, target_resolution, target_resolution, target_num_channels], [1,1,1,1], padding='SAME', name='deconv2') + b2\n",
    "        return [double_resolution, leaky_relu_and_bn(deconv2, 'bn2')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In: batch_size, resolution, resolution, input_num_channels\n",
    "# Out: batch_size, resolution, resolution, 3\n",
    "def to_rgb(X, resolution, input_num_channels, reuse=None):\n",
    "    with tf.variable_scope(\"to_rgb_\" + str(resolution)):\n",
    "        if (reuse):\n",
    "            tf.get_variable_scope().reuse_variables()\n",
    "        w = tf.get_variable('w', [1, 1, 3, input_num_channels], initializer=tf.truncated_normal_initializer(stddev=np.sqrt(2.0 / input_num_channels)))\n",
    "        b = tf.get_variable('b', [3], initializer = tf.truncated_normal_initializer(stddev=0.02))\n",
    "        return tf.nn.conv2d_transpose(X, w, [batch_size, resolution, resolution, 3], [1,1,1,1], padding='SAME', name='conv') + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_rgb_for_phase(X, phase, reuse=None):\n",
    "    return tf.case([\n",
    "        (tf.equal(phase, tf.constant(0.0)), lambda: to_rgb(X, 4, 128, reuse)),\n",
    "        (tf.equal(phase, tf.constant(1.0)), lambda: to_rgb(X, 8, 64, reuse)),\n",
    "        (tf.equal(phase, tf.constant(2.0)), lambda: to_rgb(X, 16, 32, reuse)),\n",
    "        (tf.equal(phase, tf.constant(3.0)), lambda: to_rgb(X, 32, 16, reuse)),\n",
    "    ], default=lambda: tf.zeros((1,4,4,128), tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def doubled_for_phase(X, phase):\n",
    "#     return tf.case([\n",
    "#         (tf.equal(phase, tf.constant(1)), lambda: tf.image.resize_nearest_neighbor(block, [8, 8])),\n",
    "#         (tf.equal(phase, tf.constant(2)), lambda: tf.image.resize_nearest_neighbor(block, [16, 16])),\n",
    "#         (tf.equal(phase, tf.constant(3)), lambda: tf.image.resize_nearest_neighbor(block, [32, 32])),\n",
    "#     ], default=lambda: tf.zeros((1,4,4,128), tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_rgb_possibly_smoothed(X, doubled_prior, phase, smoothing_coefficient):\n",
    "    new_to_rgb = to_rgb_for_phase(X, phase) \n",
    "    return tf.cond(smoothing_coefficient < 1,\n",
    "        lambda: (1 - smoothing_coefficient) * to_rgb_for_phase(doubled_prior, phase, True)  + smoothing_coefficient * new_to_rgb,\n",
    "        lambda: new_to_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In: batch_size, 128\n",
    "# Out: batch_size, 4*2^phase, 4*2^phase, 3\n",
    "def generator(z, num_images_seen, reuse=False):\n",
    "    with tf.variable_scope(\"G\"):\n",
    "        if (reuse):\n",
    "            tf.get_variable_scope().reuse_variables()\n",
    "        \n",
    "        num_blocks_to_add, smoothing_coefficient = calculate_num_blocks_to_add_and_smoothing_coefficient(num_images_seen)\n",
    "        phase = num_blocks_to_add\n",
    "        z_reshaped = tf.reshape(z, [batch_size, 1, 1, 128], name='z_reshape')\n",
    "        \n",
    "        X = initial_generator_block(z_reshaped)\n",
    "        \n",
    "        doubled_prior, X = tf.cond(phase >= 1, lambda: added_generator_block(X, 4, 128), lambda: [X, X])\n",
    "        doubled_prior, X = tf.cond(phase >= 2, lambda: added_generator_block(X, 8, 64), lambda: [doubled_prior, X])\n",
    "        doubled_prior, X = tf.cond(phase >= 3, lambda: added_generator_block(X, 16, 32), lambda: [doubled_prior, X])\n",
    "\n",
    "        return to_rgb_possibly_smoothed(X, doubled_prior, phase, smoothing_coefficient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [batch_size, None, None, 3], name=\"X\")\n",
    "z = tf.placeholder(tf.float32, [batch_size, 128], name=\"z\")\n",
    "num_images_seen = tf.placeholder(tf.float32, name='num_images_seen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Dx = discriminator(X, num_images_seen)\n",
    "Gz = generator(z, num_images_seen, False)\n",
    "Dg = discriminator(Gz, num_images_seen, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhUgocn4hEoqcX4iEIucXIqHI+YVIKP8fLHdcOprit2MAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10ea8f190>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149.105143229\n",
      "39.1494575394\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    z_batch = np.random.normal(0, 1, size=[batch_size, 128])\n",
    "    generated_images = sess.run(Gz, feed_dict={z: z_batch, num_images_seen: 9999999})\n",
    "    generated_image = generated_images[0, :, :, :]\n",
    "    \n",
    "    g1 = scipy.misc.imresize(generated_image, (32, 32))\n",
    "    plt.imshow(g1)\n",
    "    plt.show()\n",
    "    print(np.mean(g1))\n",
    "    print(np.var(g1) ** 0.5)\n",
    "\n",
    "#     g2 = generated_image.reshape(32, 32, 3, order='F')\n",
    "#     plt.imshow(g2)\n",
    "#     plt.show()\n",
    "#     print(np.mean(g2))\n",
    "#     print(np.var(g2) ** 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_cost_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=Dx, labels=tf.ones_like(Dx)))\n",
    "d_cost_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=Dg, labels=tf.zeros_like(Dg)))\n",
    "g_cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=Dg, labels=tf.ones_like(Dg)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t_vars = tf.trainable_variables()\n",
    "d_vars = [var for var in t_vars if 'D/' in var.name]\n",
    "g_vars = [var for var in t_vars if 'G/' in var.name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer_d_real = tf.train.AdamOptimizer(learning_rate=0.001).minimize(d_cost_real, var_list=d_vars)\n",
    "optimizer_d_fake = tf.train.AdamOptimizer(learning_rate=0.001).minimize(d_cost_fake, var_list=d_vars)\n",
    "optimizer_g = tf.train.AdamOptimizer(learning_rate=0.001).minimize(g_cost, var_list=g_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_num_params(varbs):\n",
    "    total_parameters = 0\n",
    "    for variable in varbs:\n",
    "        # shape is an array of tf.Dimension\n",
    "        shape = variable.get_shape()\n",
    "        variable_parameters = 1\n",
    "        for dim in shape:\n",
    "            variable_parameters *= dim.value\n",
    "        total_parameters += variable_parameters\n",
    "    print(total_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All:\n",
      "1115045\n",
      "D:\n",
      "558121\n",
      "G:\n",
      "556924\n"
     ]
    }
   ],
   "source": [
    "print(\"All:\")\n",
    "print_num_params(t_vars)\n",
    "print(\"D:\")\n",
    "print_num_params(d_vars)\n",
    "print(\"G:\")\n",
    "print_num_params(g_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New image size: Tensor(\"pow:0\", shape=(), dtype=float32)\n",
      "Target:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "an integer is required",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-923b73156fe8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mim\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Target:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m                     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmisc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'F'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimage_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m                     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/drufener/anaconda/lib/python2.7/site-packages/scipy/misc/pilutil.pyc\u001b[0m in \u001b[0;36mimresize\u001b[0;34m(arr, size, interp, mode)\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m     \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'nearest'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lanczos'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bilinear'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bicubic'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cubic'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 490\u001b[0;31m     \u001b[0mimnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minterp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    491\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfromimage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimnew\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/drufener/anaconda/lib/python2.7/site-packages/PIL/Image.pyc\u001b[0m in \u001b[0;36mresize\u001b[0;34m(self, size, resample)\u001b[0m\n\u001b[1;32m   1554\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGBa'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGBA'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1556\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1558\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mangle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNEAREST\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcenter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranslate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: an integer is required"
     ]
    }
   ],
   "source": [
    "sample = None\n",
    "with tf.Session() as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    num_training_images = X_train.shape[0]\n",
    "    num_images_seen = 0\n",
    "    prior_image_size = -1\n",
    "    prior_num_blocks_to_add = -1\n",
    "    for epoch in range(num_epochs):\n",
    "        for i in range(0, X_train.shape[0], batch_size):\n",
    "            num_blocks_to_add, _ = calculate_num_blocks_to_add_and_smoothing_coefficient(num_images_seen)\n",
    "            image_size = 2 ** (3 + num_blocks_to_add)\n",
    "            \n",
    "            if prior_image_size != image_size:\n",
    "                print(\"New image size: \" + str(image_size))\n",
    "                for im in X_train[0:batch_size]:\n",
    "                    print(\"Target:\")\n",
    "                    plt.imshow(scipy.misc.imresize(im.reshape([32, 32, 3], order='F'), (image_size, image_size, 3)))\n",
    "                    plt.show()\n",
    "                        \n",
    "            if prior_num_blocks_to_add != num_blocks_to_add:\n",
    "                print(\"New num_block_to_add: \" + str(num_blocks_to_add))\n",
    "            \n",
    "            original_real_batch = X_train[0:batch_size] # TODO: X_train[i:i + batch_size]\n",
    "            real_batch = map(lambda(im): scipy.misc.imresize(im.reshape(32, 32, 3, order='F'), (image_size, image_size, 3)), original_real_batch)\n",
    "            z_batch = np.random.normal(0, 1, size=[batch_size, zdim])\n",
    "            _, __, cost_real, cost_fake = session.run([optimizer_d_real, optimizer_d_fake, d_cost_real, d_cost_fake], feed_dict={X: real_batch, z: z_batch })\n",
    "            \n",
    "            num_images_seen += len(real_batch)\n",
    "            if num_images_seen >= d_warm_up:\n",
    "                _, gen_cost = session.run([optimizer_g, g_cost], feed_dict={z: z_batch})\n",
    "                if verbose and i % (print_frequency * batch_size) == 0:\n",
    "                    print \"# images seen: \" + str(num_images_seen)\n",
    "                    print \"Cost Real: \" + str(cost_real)\n",
    "                    print \"Cost Fake: \" + str(cost_fake)\n",
    "                    print \"g_cost:\" + str(gen_cost)\n",
    "                    print \"num_trainable_params: \"\n",
    "                    print_num_params()\n",
    "                    print(\"num to add: \" + str(num_blocks_to_add))\n",
    "                    print(\"image size: \") + str(image_size)\n",
    "\n",
    "                    demo_batch_size = 5\n",
    "                    z_batch = np.random.normal(0, 1, size=[demo_batch_size, zdim])\n",
    "                    generated_images = generator(z, zdim, demo_batch_size, True)\n",
    "                    images = session.run(generated_images, {z: z_batch})\n",
    "                    sample = images[0]\n",
    "                    for i, im in enumerate(images[0:demo_batch_size]):\n",
    "                        print(\"Generated:\")\n",
    "                        plt.imshow(scipy.misc.imresize(im, (image_size, image_size, 3)))\n",
    "                        plt.show()\n",
    "                    print(\"\")\n",
    "            prior_num_blocks_to_add = num_blocks_to_add\n",
    "            prior_image_size = image_size"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
