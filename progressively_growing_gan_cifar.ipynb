{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    import cPickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = cPickle.load(fo)\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_1 = unpickle('cifar-10-batches-py/data_batch_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 3072)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = batch_1['data']\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train = batch_1['labels']\n",
    "len(Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### data\n",
    "A 10000x3072 numpy array of uint8s. Each row of the array stores a 32x32 colour image. The first 1024 entries contain the red channel values, the next 1024 the green, and the final 1024 the blue. The image is stored in row-major order, so that the first 32 entries of the array are the red channel values of the first row of the image.\n",
    "#### labels\n",
    "A list of 10000 numbers in the range 0-9. The number at index i indicates the label of the ith image in the array data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x11bc36dd0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFwAAABZCAYAAACzIkPrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAD+ZJREFUeJztnFuMXedVx39r385lLmcuHt8nceyWQhBQJFRUFaQqCAnx\n0vJARZHSIlEVCYHgDcQTL5X6ALwiBVGJByRAAkQfgiiCpqIhpG6sNE3i2k7GY2d8GXs8tzNzbvvy\n8bDW3ufMeDw+43F2rPr8pdHes2/fd9b+f2utb631bXHOMUJ58D7qDjxtGAm8ZIwEXjJGAi8ZI4GX\njJHAS8ZI4CXjUAIXkV8TkUsi8p6I/Onj6tSPM+RRJz4i4gOXgV8FloDzwBedc+8+vu79+CE4xL2f\nAt5zzi0AiMg/AJ8DHijwer3mpqYapHFMlmXofb6eFN1UKhUqlcqO+3q9Hp3tbQC63e6O6xHB83Sg\n+p4+y/d9fN/2g6A4BuB5QX/f1/vE7vfEA+/+QX8fJd3Ajgi3bt5gfW1Ndl+2Fw4j8FPABwP/LwG/\nuPsiEfkq8FWARmOCr3zlRTZu36Kz3dEOVMb0Qvuh5z52jrPnzukxG303lj7g3fPnAVhcWAAgNbl4\nYUClVgdgamISgMlGg8lGA4DpmWm07RkA6uPTTEzoudq43let27Y2hh/VAMjsjWaA2/0OUu1XlmV4\nvseXfvs395PTDhxG4EPBOfcS8BLA/DPzbnruJHOzx3jm9LMATM8cAaAnIQASRORqrtNpA/CJ42c4\n95M/C8DC5csAbKytArC+usr1a1cB+OC6bgOBWqTPS3stAMJAWV2tThNUqro/oS+7NjEOwNTsHFMz\nJwFoTOmLGm9MMtHQF1kbnwDAr+gL8oOAwPcZitqGwwj8BjA/8P9pO/ZAVKs1fuITP8WVS1dY2WgC\nUDe2VWoqoE5niyiKAMh6KvDtbou5oycA+PSpM9r49UUAWhvrfPozvwTArWVtPgorTJlw3n5LR8Z3\n/utlANI7C3ieisiJbv2KthdFEX6mx0LrQ1CpUB9T1jdmjwEwMXMagOnpGWZnZ2k1m/v97B04jJdy\nHvi4iDwnIhHwW8A3D/G8pwKPzHDnXCIifwD8B+AD33DOvbPfPb7vMT0xwdmPfZylD64BsLq6DMBk\nzvRqjchXlTIWKR/anR4uVeYliT6r0dAh3+u2SdIeAPOm+2vVKcbrUwAcmX8OgJapqW/96z/iJ7of\n+Tqqwkzvz9o9vDQGoGOjIBPhLmrg3XtX7IeYSvF8KpUKa/fuDiMy4JA63Dn3MvDyYZ7xtOFDN5qD\n6LTaXPzhD5icPUotUPau3bsDQLutLDt6/BR4KQCxuQe9xCGZstKzbRhq16enJ3n11W8DMFFTd/L5\nn/4UXWNhTx/F5NxxfWZQY21tDYB6oMytG9MrQYAE+ozc88scOLOKzun19Jr2v6PZciRJPLQMRlP7\nklEqw5M0ZnX9Lm+/+Tphomw5/py6hz37vz4+Rr2uHokzPiQZtNrKKpvbEPd0AvSjH7zBhVe+BcDY\nmLp5J+ZOcGxePYvIRsLPPP9zAAQv/j43zH5srK8A0NxUF3Nrc51tm2C12+ohxXGMM76LaH+iIH92\nSL1ex1/eHloGpQrc930mGw2utrZYua3Gsp3pcJw4chQAEaFWVT95dk594iAI6bbVn67V1F27cvki\nAK9993/wUtUb6ysqwJtLH1CZmAUgqpuPbUb2lz/7QuEWtjsqqFZLX+Z2c4PlJX0Zi1fVp7/y3nvF\nizx9Wr3gWXMPa7UaMzMzLHzta0PLYKRSSkapDEc8CCpMTc+wvLAIQNWYu7l0HYDl5WXeuHABgOdN\nDdTHJul1NRRg5OStC98DYGNznSRRhmepxWegmK3GPR1BW07ZXK9DJVSVUBvTGWRjWkdXNQqJPDWg\nmxvarxdeOMexY8rocQsdBFU1yFmWUa1WiXbFfvbDiOElo1SGO+foJBlRtV5E8ZJY3UFnsY7bN+/w\n/lWNib322v8B4Pkhga/Xz83ohIbYgl8eNDdVB89aTCSqREUEMM2M/eYfhmFUxEnyEdHp6LMuX7rI\nq6/8NwCLixokO3nyFCtr97SPFjUJqqrTgzAkiWOaW1tDy6BcoxmETB05yvKViwQWIu2YSiHSroSB\nUKvo/lZLPZEkjskCNZab5lmkZvAaU1P0zDfvWOh2a2ureEFbHT02aeogi7PCYG9v64u6ZAb4++df\nZ2Hhkp4zIV699n7h82fmkHu+9sX3fZIkYX19bWgZjFRKySiV4VEUMT9/hsvn/5d7GxsAtNeUgafP\nPAOAN5BQkIEZXuY0iJKYahirqeu42WzS3NZn1Oy+Ny5cYPGOPn/C3MGxuqqBSEIuX/4RAGvrGgNZ\nXLxi/98jdfp8Z6MGgTTNj1l/LKLonMPzPOJ4NNN8YlEqwz3xqPtVTsyfIba4R9JVdnR7yqj1zQ6x\n6crQWCxpRmq6ODG3zfl6f1AJCbrKwK7FXt6+coV7b7wJQL1mhtSMtHNC2+xGlrPZqOv7IRr4BDxn\n5xye2QP8YsgV50CQA6QgRgwvGaUyPEszOs0Wp07OMz6lOcb2ssYsVtdU5263uiR50DuPSacxWarH\nehbXWNvcBCCKQiSfqnfVxdzqdujGNiJsUuQbt5wMJo3t+ZbQzhx4sjNlnJrrqNh5zjmHCEWsZRiU\n7IdndDttAj9gelKNWWJ5y7zPrXabyHzytvnHWRwT2HDODann5XnPlmbbB072er2BNi3hm6sPETAB\np/f1z5FZR/J4i8j96qIoLXEHEbX1+4DXj3BIlKtSspRWa41ri1eoVXXyMDWpyd6uuVbeOszNqrrJ\nmdputejZ+Z7FRoIgr0HxiGNzGU19pFnWN2zkJQ3WCXHFSMiZmrPYZVmhnvaDK55N0c6wGDG8ZJTK\n8O3tJt87/x1uXL9KGCgztrfWtSNVjeCNj49z+oQmIDZW9dxamlIzN3JtXY/lBVJJmtFu6zTfR0fN\nXqwrVLHIfQzPsRdXRaTP6D2ee9BSwVIF3u20ef/S26yurHD2rGZ6KuZrd3rmhfQ6hJbvFDNrvgjN\nlhpXZymfir2gZLuJs5lgL9Nn6CRxp2rIxSIihQrZyyDuh72E6+1RGrcfRiqlZJSb0+zFrCzdIEsF\nMm26ZvUjd+4uATBeG6e5pdG3MFIGdjodLKlPra5Rv40NvcYlMfWaxkk22xaKTVzhY+dML/KSPJjZ\ngwz2bCQ55x6oNgZHy7AYMbxklMrwNMvYbHeoh1U2zfgFpsPrtg0D6FrcZNwifJ1OG2cxl9hZwiKx\nrYPUGJgUs0IpMuwHNXT5Od90c+ZcES3cC1mWPfDcXngow0VkXkS+LSLvisg7IvJHdnxGRP5TRK7Y\ndvpALT+leOgKCBE5AZxwzl0QkQngDeDzwO8Aq865r9tyk2nn3J/s96xaNXJnnz3KeCQ0LB02d0wr\nouoWt65WIlbvaVZnbUVTW7dv3sSzcorISo3HprXM+fbKBmubmp1pd3MmSlF0v/v3PczNy2MpeQXv\nYLw7Z/puz+Te6gZxnDyegnzn3C3glu03ReQiWoz/OeCzdtnfAa8A+wrcZSlJe4MMr6ioF0ssBFZ2\ndvzEcY4e0Sz5v7+vZYsnT5zEqplpdVSVbMf645PM6fPox1cG5biXC5irgd0zzcEwVH7NoHDz/Xy7\nn0F9EA6kw0XkDPDzwOvAMXsZALeBYw+4p1gBkQegnmYMLXARGQf+Gfhj59zmIGOcc05E9nzVgysg\nJuuhe+ZIndmZOlPT+n5Cc/M6VnJ8d+UOz57SsuP5U5p2mzsyRWJlxDff0YTvyromgHtZP9za78L+\nhlJ2uYz9nyII2a5z/d9ZrCUydVWEkQ+AodxCEQlRYf+9c+5f7PCy6fdcz985cOtPIR7KcNFX/LfA\nRefcXw2c+ibwZeDrtv23hz2rEgWcmz9CfWKccEwnPNduqoG819SEQmu7x91ntLjy+CmNqdy9e5uF\nRa1VuXHbit9t9ZsTv0j4DjMJ0cTvzskQxYo6Crr3028eA4GBHZv79ofAMCrlM8CLwA9F5E079meo\noP9JRH4XuAZ84WBNP50Yxkv5Lg9+j79ykMZ832OsMYZXmaJlXkpmayUDUTesVvFpblu6LdZk78Li\nVVZXdQQk2U62CTKgn+/3Hu5jvbiiwD7IU3jGYJdlxXLBfOIUpwmpJZnzULlnYtP7nuBooR+ENI4c\n5/qtJtduqWpI87RYWw1Qp91j3dZwilU8deOUXM6BZd+ztJ+P7CcX+rO+3b52LvfA98hMgM5+voS2\n6iHN8HOVYj53kjqcvSFxuXG2+yQDSQ+kVkaxlJJRbooN6CawdPMOS2b88rpAMlvt0EuoWwF8YKsi\n0tgVhtELTW0YmbMsGzBpOycmen4nwwVXzIzymWO+ZFw8jyhXS34/SVFk9S1Wk9nqC89leL47kN0c\nMbxklF6X0t5uEcdxUdqQxnlJg7In8D18Y6Bl4YgQMit67yX9eInCFXarX0Ih7A7iFWUPZPiWSfLy\nkohUbYbvCTWzEXmSWsQnsVhKPxqZ1xJm+L5w7wAUL7cuJUvpbDVJ2m3EOu+TD281miI+zop4ci8C\nAWdBq8TpuZ7N8gYHdFoU9Lj70pq54csKxTOwbDDUc5P1CvW6tuPZbDIIgoHYyYC/jpIjjDyW1xaH\nlsFIpZSM0ldAZEmHmcmwiA52LRzhMvXDQz8kCjQ0GJkxS7OQDWN01VzFpJpXWWUk8c7akzTL+u6g\njQDflpNHQUpjTFl8bEaXmzdq+sxq5OPlCez8wwd+QGD9KSKPFpXU77J4RNHS0DIYMbxklMpwwSHE\nzM1EzM0qa7IsN2BqFH2v36XCHcsyJltqXEP7oE1uBLudFPPSCh0+ONPMk8GRuZO1KGa8rm3V7cM2\nvp9/UcjDM3cw74fnhRQz2Nw6FzT1cJnr1zYOgRHDS0a56zQBnCMIPALTlWFoyWM/X+vYj43kE5Ne\nLykYNzFpayQtmSz45EX0Yh9F0Lj4znh2XjbhMTAJkp1xExGxovz+ZMjzwmIqX7iWRbTRAyfFKBoG\npQtcPA/f94nsE0nVqm4D+6GCFKqkv7Ymo26LWUMb8omdEy/Dz79/VQjE669KGHDXQSeZfX/dhFq8\nAa9YzN8/5/f3iwREvhLCQ/AGamAejpFKKRmP/N3CR2pM5C6wDayU1uij4wjD9/NZ59zcMBeWKnAA\nEfm+c+4XSm30EfBh9XOkUkrGSOAl46MQ+EsfQZuPgg+ln6Xr8KcdI5VSMkoT+JP8rfF9KoT/XERu\niMib9vfrh26rDJXypH9rfJ8K4S8AW865v3hcbZXF8OJb4865HpB/a/yJgHPulnPugu03gbxC+LGj\nLIHv9a3xD+UHHRa7KoQB/lBE3hKRbzyORQcjozmA3RXCwF8DZ4FPojXyf3nYNsoS+IG/NV429qoQ\nds4tO+dSp9njv0FV46FQlsCf6G+NP6hCOC/HNvwG8PZh2yolHv4o3xovGQ+qEP6iiHwSjaYvAr93\n2IZGM82SMTKaJWMk8JIxEnjJGAm8ZIwEXjJGAi8ZI4GXjJHAS8b/A+aOd29ZzgJ5AAAAAElFTkSu\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x114de3490>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import scipy.misc\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "plt.figure(figsize =(1,1))\n",
    "image = np.swapaxes(X_train[9].reshape(32, 32, 3, order='F'), 0,1)\n",
    "image = scipy.misc.imresize(image, (32,32)) \n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x11bd0d150>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRsCBxP4Lk/bymjUC2LgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x114ad11d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = np.swapaxes(X_train[9].reshape(32, 32, 3, order='F'), 0,1)\n",
    "image = scipy.misc.imresize(image, (8,8)) \n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def leaky_relu_and_bn(X, bn_name, alpha=0.3):\n",
    "    X = tf.layers.batch_normalization(X, name=bn_name)\n",
    "    return tf.nn.relu(X) - alpha * tf.nn.relu(-X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def from_rgb(X, res, reuse=None):\n",
    "    with tf.variable_scope(\"from_rgb\"):\n",
    "        if (reuse):\n",
    "            tf.get_variable_scope().reuse_variables()\n",
    "        Xn = tf.layers.batch_normalization(X, name='bn0' + str(res))\n",
    "        w_1 = tf.get_variable('w1' + str(res), [1, 1, 3, 16], initializer=tf.truncated_normal_initializer(stddev=np.sqrt(2.0 / 16)))\n",
    "        b_1 = tf.get_variable('b1' + str(res), [16], initializer = tf.truncated_normal_initializer(stddev=0.02))\n",
    "        l_1a = tf.nn.conv2d(Xn, w_1, [1,1,1,1], padding='SAME') + b_1;\n",
    "        l_1b = leaky_relu_and_bn(l_1a, 'bn1' + str(res))\n",
    "\n",
    "        w_2 = tf.get_variable('w2' + str(res), [3, 3, 16, 16], initializer=tf.truncated_normal_initializer(stddev=np.sqrt(2.0 / 16)))\n",
    "        b_2 = tf.get_variable('b2' + str(res), [16], initializer = tf.truncated_normal_initializer(stddev=0.02))\n",
    "        l_2a = tf.nn.conv2d(l_1b, w_2, [1,1,1,1], padding='SAME') + b_2;\n",
    "        l_2b = leaky_relu_and_bn(l_2a, 'bn2' + str(res))\n",
    "\n",
    "        w_3 = tf.get_variable('w3' + str(res), [3, 3, 16, 32], initializer=tf.truncated_normal_initializer(np.sqrt(2.0 / 16)))\n",
    "        b_3 = tf.get_variable('b3' + str(res), [32], initializer = tf.truncated_normal_initializer(stddev=0.02))    \n",
    "        l_3a = tf.nn.conv2d(l_2b, w_3, [1,1,1,1], padding='SAME') + b_3;\n",
    "        l_3b = leaky_relu_and_bn(l_3a, 'bn3' + str(res))\n",
    "\n",
    "        return tf.nn.avg_pool(l_3b, [1, 2, 2, 1], [1, 1, 1, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculate_num_blocks_to_add_and_smoothing_coefficient(num_images_seen):\n",
    "    num_images_before_adding_block = tf.constant(1600000, tf.float32)\n",
    "    num_blocks_to_add = tf.cast(tf.floor(tf.divide(num_images_seen, num_images_before_adding_block)), tf.float32)\n",
    "    r = tf.subtract(num_images_seen, tf.multiply(num_blocks_to_add, num_images_before_adding_block))\n",
    "    \n",
    "    smoothing_coefficient = tf.cond(num_blocks_to_add >= tf.constant(3, tf.float32), lambda: tf.constant(1, tf.float32), lambda: tf.minimum(\n",
    "        tf.constant(1, tf.float32), tf.divide(r, tf.divide(num_images_before_adding_block, tf.constant(2, tf.float32)))))\n",
    "    num_blocks_to_add = tf.cond(num_blocks_to_add >= tf.constant(3, tf.float32), lambda: tf.minimum(num_blocks_to_add, tf.constant(2, tf.float32)), lambda: num_blocks_to_add)\n",
    "    \n",
    "    return [num_blocks_to_add, smoothing_coefficient]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def new_d_block(X, num_channels):\n",
    "    print(\"ndb\" + str(num_channels))\n",
    "    with tf.variable_scope(\"new_d_block\"):\n",
    "        w_1 = tf.get_variable(str(num_channels) + '_w1', [3, 3, num_channels, num_channels], initializer=tf.truncated_normal_initializer(stddev=np.sqrt(2.0 / num_channels)))\n",
    "        b_1 = tf.get_variable(str(num_channels) + '_b1', [num_channels], initializer = tf.truncated_normal_initializer(stddev=0.02))    \n",
    "        conv_1 = tf.nn.conv2d(X, w_1, [1,1,1,1], padding='SAME', name=str(num_channels) + '_conv1') + b_1\n",
    "        a_1 = leaky_relu_and_bn(conv_1, str(num_channels) + '_bn1d')\n",
    "\n",
    "        w_2 = tf.get_variable(str(num_channels) + '_w2', [3, 3, num_channels, 2 * num_channels], initializer=tf.truncated_normal_initializer(stddev=np.sqrt(2.0 / num_channels)))\n",
    "        b_2 = tf.get_variable(str(num_channels) + '_b2', [2 * num_channels], initializer = tf.truncated_normal_initializer(stddev=0.02))    \n",
    "        conv_2 = tf.nn.conv2d(a_1, w_2, [1,1,1,1], padding='SAME', name=str(num_channels) + '_conv2') + b_2\n",
    "        a_2 = leaky_relu_and_bn(conv_2, str(num_channels) + '_bn2d')  \n",
    "\n",
    "        return tf.nn.avg_pool(a_2, [1, 2, 2, 1], [1, 1, 1, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def smooth_first_block(X, num_blocks_to_add, smoothing_coefficient, num_channels, first_new_d_block):\n",
    "    halved = tf.nn.avg_pool(X, [1, 2, 2, 1], [1, 1, 1, 1], padding='SAME')\n",
    "    prior_from_rgb = get_sized_from_rgb(X, num_blocks_to_add - 1, True) #TODO: Does it make sense to reuse here or keep training?\n",
    "    return (1 - smoothing_coefficient) * prior_from_rgb + smoothing_coefficient * first_new_d_block\n",
    "\n",
    "def add_one_or_more_blocks(X, num_blocks_to_add, smoothing_coefficient, num_channels, block):\n",
    "    first_new_d_block = new_d_block(block, num_channels)\n",
    "    block = tf.cond(smoothing_coefficient < 1, lambda: smooth_first_block(X, num_blocks_to_add, smoothing_coefficient, num_channels, first_new_d_block), lambda: first_new_d_block)\n",
    "    #TODO: Don't do tf.constant(num_channels) just to return a tensor from cond, here and elsewhere\n",
    "    num_channels, block = tf.cond(num_blocks_to_add > 1, lambda: (tf.constant(num_channels), new_d_block(block, num_channels * 2)), lambda: (tf.constant(num_channels), block))\n",
    "    return (num_channels, block)\n",
    "\n",
    "def get_sized_from_rgb(X, num_blocks_to_add, reuse=None):\n",
    "    return tf.case([\n",
    "            (tf.equal(num_blocks_to_add, tf.constant(0, tf.float32)), lambda: from_rgb(X, 8, reuse)),\n",
    "            (tf.equal(num_blocks_to_add, tf.constant(1, tf.float32)), lambda: from_rgb(X, 16, reuse)),\n",
    "            (tf.equal(num_blocks_to_add, tf.constant(2, tf.float32)), lambda: from_rgb(X, 32, reuse)),\n",
    "        ], default=lambda: tf.zeros((1,1,1,32), tf.float32))\n",
    "\n",
    "def discriminator(X, num_images_seen, reuse=False):\n",
    "    with tf.variable_scope(\"D\"):\n",
    "        if (reuse):\n",
    "            tf.get_variable_scope().reuse_variables()\n",
    "\n",
    "        num_blocks_to_add, smoothing_coefficient = calculate_num_blocks_to_add_and_smoothing_coefficient(num_images_seen)\n",
    "        block = get_sized_from_rgb(X, num_blocks_to_add)\n",
    "    \n",
    "        num_channels = 32\n",
    "        num_channels, block = tf.cond(num_blocks_to_add > 0, lambda: add_one_or_more_blocks(X, num_blocks_to_add, smoothing_coefficient, num_channels, block), lambda: (tf.constant(num_channels), block))\n",
    "\n",
    "        w_1 = tf.get_variable('final_w1', [3, 3, num_channels, num_channels], initializer=tf.truncated_normal_initializer(stddev=np.sqrt(2.0 / num_channels)))\n",
    "        b_1 = tf.get_variable('final_b1', [num_channels], initializer = tf.truncated_normal_initializer(stddev=0.02))    \n",
    "        final_1a = tf.nn.conv2d(block, w_1, [1,1,1,1], padding='SAME') + b_1\n",
    "        final_1b = leaky_relu_and_bn(final_1a, 'final_bn1d')\n",
    "\n",
    "        w_2 = tf.get_variable('final_w2', [4, 4, num_channels, num_channels], initializer=tf.truncated_normal_initializer(stddev=np.sqrt(2.0 / num_channels)))\n",
    "        b_2 = tf.get_variable('final_b2', [num_channels], initializer = tf.truncated_normal_initializer(stddev=np.sqrt(2.0 / num_channels)))    \n",
    "        final_2a = tf.nn.conv2d(final_1b, w_2, [1,1,1,1], padding='VALID') + b_2\n",
    "        final_2b = leaky_relu_and_bn(final_2a, 'final_bn2d')\n",
    "        return tf.layers.dense(final_2b, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_rgb(X, starting_resolution, batch_size):   \n",
    "    target_resolution = 2 * starting_resolution\n",
    "    l0 = tf.image.resize_nearest_neighbor(X, [target_resolution, target_resolution], name=\"to_rgm_resize\") \n",
    "\n",
    "    w_1 = tf.get_variable('to_rgb_w1' + str(target_resolution), [3, 3, 16, 32], initializer=tf.truncated_normal_initializer(stddev=np.sqrt(2.0 / 32)))\n",
    "    b_1 = tf.get_variable('to_rgb_b1' + str(target_resolution), [16], initializer = tf.truncated_normal_initializer(stddev=np.sqrt(2.0 / 16)))\n",
    "    l_1a = tf.nn.conv2d_transpose(l0, w_1, [batch_size, target_resolution, target_resolution, 16], [1,1,1,1], padding='SAME', name='to_rgb_l1' + str(target_resolution)) + b_1\n",
    "    l_1b = leaky_relu_and_bn(l_1a, 'to_rgb_bn1' + str(target_resolution))\n",
    "    \n",
    "    w_2 = tf.get_variable('to_rgb_w2' + str(target_resolution), [3, 3, 16, 16], initializer=tf.truncated_normal_initializer(stddev=np.sqrt(2.0 / 16)))\n",
    "    b_2 = tf.get_variable('to_rgb_b2' + str(target_resolution), [16], initializer = tf.truncated_normal_initializer(stddev=0.02))\n",
    "    l_2a = tf.nn.conv2d_transpose(l_1b, w_2, [batch_size, target_resolution, target_resolution, 16], [1,1,1,1], padding='SAME', name='to_rgb_l2' + str(target_resolution)) + b_2\n",
    "    l_2b = leaky_relu_and_bn(l_2a, 'to_rgb_bn2' + str(target_resolution))\n",
    "    \n",
    "    w_3 = tf.get_variable('to_rgb_w3' + str(target_resolution), [1, 1, 3, 16], initializer=tf.truncated_normal_initializer(stddev=np.sqrt(2.0 / 16)))\n",
    "    b_3 = tf.get_variable('to_rgb_b3' + str(target_resolution), [3], initializer = tf.truncated_normal_initializer(stddev=0.02))\n",
    "    return tf.nn.conv2d_transpose(l_2b, w_3, [batch_size, target_resolution, target_resolution, 3], [1,1,1,1], padding='SAME', name='to_rgb_l3' + str(target_resolution)) + b_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def new_g_block(X, starting_resolution, num_channels):\n",
    "    target_resolution = 2 * starting_resolution\n",
    "\n",
    "    w_1 = tf.get_variable(str(target_resolution) + 'w1', [3, 3, num_channels / 2, num_channels], initializer=tf.truncated_normal_initializer(stddev=np.sqrt(2.0 / 32)))\n",
    "    b_1 = tf.get_variable(str(target_resolution) + 'b1', [num_channels / 2], initializer = tf.truncated_normal_initializer(stddev=np.sqrt(2.0 / 16)))\n",
    "    l_1a = tf.nn.conv2d_transpose(l0, w_1, [batch_size, size, size, 16], [1,1,1,1], padding='SAME', name=str(target_resolution) + 'deconv1') + b_1\n",
    "    l_1b = leaky_relu_and_bn(l_1a, 'bn1g')\n",
    "    \n",
    "    w_2 = tf.get_variable(str(target_resolution) + 'w2', [3, 3, num_channels / 2, num_channels / 2], initializer=tf.truncated_normal_initializer(stddev=np.sqrt(2.0 / 16)))\n",
    "    b_2 = tf.get_variable(str(target_resolution) + 'b2', [num_channels / 2], initializer = tf.truncated_normal_initializer(stddev=0.02))\n",
    "    l_2a = tf.nn.conv2d_transpose(l_1b, w_2, [batch_size, target_resolution, target_resolution, num_channels / 2], [1,1,1,1], padding='SAME', name=str(target_resolution) + 'deconv2') + b_2\n",
    "    return leaky_relu_and_bn(l_2a, 'bn2g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generator(z, num_images_seen, batch_size, reuse=False):\n",
    "    with tf.variable_scope(\"G\"):\n",
    "        if (reuse):\n",
    "            tf.get_variable_scope().reuse_variables()\n",
    "        \n",
    "        num_blocks_to_add, smoothing_coefficient = calculate_num_blocks_to_add_and_smoothing_coefficient(num_images_seen)\n",
    "        zdim = 2 ** (5 + num_blocks_to_add)\n",
    "        z_rehaped = tf.reshape(z, [batch_size, 1, 1, zdim], name='z_reshape')\n",
    "        w_1 = tf.get_variable('initial_w1', [4, 4, zdim, zdim], initializer=tf.truncated_normal_initializer(stddev=np.sqrt(2.0 / zdim)))\n",
    "        b_1 = tf.get_variable('initial_b1', [zdim], initializer = tf.truncated_normal_initializer(stddev=0.02))    \n",
    "        initial_1a = tf.nn.conv2d_transpose(z_rehaped, w_1, [batch_size, 4, 4, zdim], [1, 1, 1, 1], padding='VALID', name='initial_l1') + b_1\n",
    "        initial_1b = leaky_relu_and_bn(initial_1a, 'initial_bn1')\n",
    "        \n",
    "        w_2 = tf.get_variable('initial_w2', [3, 3, zdim, zdim], initializer=tf.truncated_normal_initializer(stddev=np.sqrt(2.0 / zdim)))\n",
    "        b_2 = tf.get_variable('initial_b2', [zdim], initializer = tf.truncated_normal_initializer(stddev=0.02))    \n",
    "        initial_2a = tf.nn.conv2d_transpose(initial_1b, w_2, [batch_size, 4, 4, zdim], [1, 1, 1, 1], padding='SAME', name='initial_l2') + b_2\n",
    "        block = leaky_relu_and_bn(initial_2a, 'initial_bn2')\n",
    "\n",
    "        resolution = 4\n",
    "        num_channels = zdim\n",
    "        for i in range(num_blocks_to_add):\n",
    "            doubled = tf.image.resize_nearest_neighbor(block, [target_resolution, target_resolution], name=\"to_rgb_resize\") \n",
    "            if (i < num_blocks_to_add - 1 or smoothing_coefficient == 1):\n",
    "                block = new_g_block(doubled, resolution, num_channels)\n",
    "                resolution = resolution * 2\n",
    "                num_channels = num_channels / 2\n",
    "            else:\n",
    "                prior_rgb = to_rgb(doubled, resolution, batch_size)\n",
    "                new_block = new_g_block(doubled, num_channels / 2)\n",
    "                new_rgb = to_rgb(new_block, resolution * 2, batch_size)\n",
    "                return (1 - smoothing_coefficient) * prior_rgb + smoothing_coefficient * new_rgb\n",
    "\n",
    "        return to_rgb(block, resolution, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, None, None, 3], name=\"X\")\n",
    "z = tf.placeholder(tf.float32, [None, None], name=\"z\")\n",
    "num_images_seen = tf.placeholder(tf.float32, name='num_images_seen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "zdim = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndb32\n",
      "ndb64\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Expected int32, got 2.0 of type 'float' instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-6fca95ada26d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mDx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_images_seen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mGz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_images_seen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mDg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_images_seen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-271451498248>\u001b[0m in \u001b[0;36mdiscriminator\u001b[0;34m(X, num_images_seen, reuse)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mnum_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_blocks_to_add\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0madd_one_or_more_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_blocks_to_add\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmoothing_coefficient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mw_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'final_w1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_channels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtruncated_normal_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstddev\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.0\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnum_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mb_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'final_b1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnum_channels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitializer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtruncated_normal_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstddev\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.02\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mfinal_1a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'SAME'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb_1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/drufener/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.pyc\u001b[0m in \u001b[0;36mr_binary_op_wrapper\u001b[0;34m(y, x)\u001b[0m\n\u001b[1;32m    834\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mr_binary_op_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 836\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"x\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    837\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/drufener/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, preferred_dtype)\u001b[0m\n\u001b[1;32m    637\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m       \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 639\u001b[0;31m       as_ref=False)\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/drufener/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m           \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/drufener/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/constant_op.pyc\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    111\u001b[0m                                          as_ref=False):\n\u001b[1;32m    112\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/drufener/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/constant_op.pyc\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name, verify_shape)\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0mtensor_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m   tensor_value.tensor.CopyFrom(\n\u001b[0;32m--> 102\u001b[0;31m       tensor_util.make_tensor_proto(value, dtype=dtype, shape=shape, verify_shape=verify_shape))\n\u001b[0m\u001b[1;32m    103\u001b[0m   \u001b[0mdtype_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m   const_tensor = g.create_op(\n",
      "\u001b[0;32m/Users/drufener/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/tensor_util.pyc\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[0;34m(values, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    368\u001b[0m       \u001b[0mnparray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp_dt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m       \u001b[0m_AssertCompatible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m       \u001b[0mnparray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp_dt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m       \u001b[0;31m# check to them.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/drufener/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/tensor_util.pyc\u001b[0m in \u001b[0;36m_AssertCompatible\u001b[0;34m(values, dtype)\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m       raise TypeError(\"Expected %s, got %s of type '%s' instead.\" %\n\u001b[0;32m--> 302\u001b[0;31m                       (dtype.name, repr(mismatch), type(mismatch).__name__))\n\u001b[0m\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Expected int32, got 2.0 of type 'float' instead."
     ]
    }
   ],
   "source": [
    "Dx = discriminator(X, num_images_seen)\n",
    "Gz = generator(z, num_images_seen, batch_size, False)\n",
    "Dg = discriminator(Gz, num_images_seen, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    z_batch = np.random.normal(0, 1, size=[batch_size, zdim])\n",
    "    generated_images = sess.run(Gz, feed_dict={z: z_batch})\n",
    "    generated_image = generated_images[0, :, :, :]\n",
    "    \n",
    "    g1 = scipy.misc.imresize(generated_image, (8, 8))\n",
    "    plt.imshow(g1)\n",
    "    plt.show()\n",
    "    print(np.mean(g1))\n",
    "    print(np.var(g1) ** 0.5)\n",
    "\n",
    "    g2 = generated_image.reshape(8, 8, 3, order='F')\n",
    "    plt.imshow(g2)\n",
    "    plt.show()\n",
    "    print(np.mean(g2))\n",
    "    print(np.var(g2) ** 0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d_cost_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=Dx, labels=tf.ones_like(Dx)))\n",
    "d_cost_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=Dg, labels=tf.zeros_like(Dg)))\n",
    "g_cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=Dg, labels=tf.ones_like(Dg)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tvars = tf.trainable_variables()\n",
    "d_vars = [var for var in tvars if 'D/' in var.name]\n",
    "g_vars = [var for var in tvars if 'G/' in var.name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimizer_d_real = tf.train.AdamOptimizer(learning_rate=0.001).minimize(d_cost_real, var_list=d_vars)\n",
    "optimizer_d_fake = tf.train.AdamOptimizer(learning_rate=0.001).minimize(d_cost_fake, var_list=d_vars)\n",
    "optimizer_g = tf.train.AdamOptimizer(learning_rate=0.001).minimize(g_cost, var_list=g_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_num_params():\n",
    "    total_parameters = 0\n",
    "    for variable in tf.trainable_variables():\n",
    "        # shape is an array of tf.Dimension\n",
    "        shape = variable.get_shape()\n",
    "        variable_parameters = 1\n",
    "        for dim in shape:\n",
    "            variable_parameters *= dim.value\n",
    "        total_parameters += variable_parameters\n",
    "    print(total_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print_num_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_epochs = 1000000000\n",
    "verbose = True\n",
    "sample = None\n",
    "d_warm_up = 0\n",
    "with tf.Session() as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    num_training_images = X_train.shape[0]\n",
    "    num_images_seen = 0\n",
    "    prior_image_size = -1\n",
    "    prior_num_blocks_to_add = -1\n",
    "    for epoch in range(num_epochs):\n",
    "        for i in range(0, X_train.shape[0], batch_size):\n",
    "            num_blocks_to_add, _ = calculate_num_blocks_to_add_and_smoothing_coefficient(num_images_seen)\n",
    "            image_size = 2 ** (3 + num_blocks_to_add)\n",
    "            \n",
    "            if prior_image_size != image_size:\n",
    "                print(\"New image size: \" + str(image_size))\n",
    "                for im in X_train[0:batch_size]:\n",
    "                    print(\"Target:\")\n",
    "                    plt.imshow(scipy.misc.imresize(im.reshape([32, 32, 3], order='F'), (image_size, image_size, 3)))\n",
    "                    plt.show()\n",
    "                        \n",
    "            if prior_num_blocks_to_add != num_blocks_to_add:\n",
    "                print(\"New num_block_to_add: \" + str(num_blocks_to_add))\n",
    "            \n",
    "            original_real_batch = X_train[0:batch_size] # TODO: X_train[i:i + batch_size]\n",
    "            real_batch = map(lambda(im): scipy.misc.imresize(im.reshape(32, 32, 3, order='F'), (image_size, image_size, 3)), original_real_batch)\n",
    "            z_batch = np.random.normal(0, 1, size=[batch_size, zdim])\n",
    "            _, __, cost_real, cost_fake = session.run([optimizer_d_real, optimizer_d_fake, d_cost_real, d_cost_fake], feed_dict={X: real_batch, z: z_batch })\n",
    "            \n",
    "            num_images_seen += len(real_batch)\n",
    "            if num_images_seen >= d_warm_up:\n",
    "                _, gen_cost = session.run([optimizer_g, g_cost], feed_dict={z: z_batch})\n",
    "                if verbose and i % (10000 * batch_size) == 0:\n",
    "                    print \"# images seen: \" + str(num_images_seen)\n",
    "                    print \"Cost Real: \" + str(cost_real)\n",
    "                    print \"Cost Fake: \" + str(cost_fake)\n",
    "                    print \"g_cost:\" + str(gen_cost)\n",
    "                    print \"num_trainable_params: \"\n",
    "                    print_num_params()\n",
    "                    print(\"num to add: \" + str(num_blocks_to_add))\n",
    "                    print(\"image size: \") + str(image_size)\n",
    "\n",
    "                    demo_batch_size = 5\n",
    "                    z_batch = np.random.normal(0, 1, size=[demo_batch_size, zdim])\n",
    "                    generated_images = generator(z, zdim, demo_batch_size, True)\n",
    "                    images = session.run(generated_images, {z: z_batch})\n",
    "                    sample = images[0]\n",
    "                    for i, im in enumerate(images[0:demo_batch_size]):\n",
    "                        print(\"Generated:\")\n",
    "                        plt.imshow(scipy.misc.imresize(im, (image_size, image_size, 3)))\n",
    "                        plt.show()\n",
    "                    print(\"\")\n",
    "            prior_num_blocks_to_add = num_blocks_to_add\n",
    "            prior_image_size = image_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
